import os
import json
import time
import gzip
from typing import List, Dict, Any, Optional
import urllib.request
import urllib.error

# Try to import brotli for Brotli decompression
try:
    import brotli
    BROTLI_AVAILABLE = True
except ImportError:
    BROTLI_AVAILABLE = False


class NebulaBlockClient:
    """
    Lightweight client for NebulaBlock inference service.

     This assumes OpenAI/Cohere-like JSON shapes but keeps endpoints configurable
    so you can adapt without changing code.

    Configure via env vars or constructor args:
      - NEBULABLOCK_BASE_URL (default: https://dev-llm-proxy.nebulablock.com/v1)
      - NEBULABLOCK_API_KEY (e.g., sk-...)
      - NEBULABLOCK_EMBEDDINGS_PATH (default: /embeddings)
      - NEBULABLOCK_RERANK_PATH (default: /rerank)
      - NEBULABLOCK_CHAT_PATH (default: /chat/completions)

      - NEBULABLOCK_EMBEDDING_MODEL (default: Qwen/Qwen3-Embedding-8B)
      - NEBULABLOCK_RERANKER_MODEL (default: BAAI/bge-reranker-v2-m3)
      - NEBULABLOCK_CHAT_MODEL (default: Mistral-Small-24B-Instruct-2501)
    """

    def __init__(
        self,
        base_url: Optional[str] = None,
        api_key: Optional[str] = None,
        embedding_model: Optional[str] = None,
        reranker_model: Optional[str] = None,
        chat_model: Optional[str] = None,
        embeddings_path: Optional[str] = None,
        rerank_path: Optional[str] = None,
        chat_path: Optional[str] = None,
        timeout: float = 60.0,
    ) -> None:
        self.base_url = (
            base_url
            or os.environ.get("NEBULABLOCK_BASE_URL")
            or "https://dev-llm-proxy.nebulablock.com/v1"
        ).rstrip("/")
        self.api_key = api_key or os.environ.get("NEBULABLOCK_API_KEY", "")

        self.embedding_model = embedding_model or os.environ.get(
            "NEBULABLOCK_EMBEDDING_MODEL", "Qwen/Qwen3-Embedding-8B"
        )
        self.reranker_model = reranker_model or os.environ.get(
            "NEBULABLOCK_RERANKER_MODEL", "BAAI/bge-reranker-v2-m3"
        )
        self.chat_model = chat_model or os.environ.get(
            "NEBULABLOCK_CHAT_MODEL", "Mistral-Small-24B-Instruct-2501"
        )

        self.embeddings_path = embeddings_path or os.environ.get(
            "NEBULABLOCK_EMBEDDINGS_PATH", "/embeddings"
        )
        self.rerank_path = rerank_path or os.environ.get("NEBULABLOCK_RERANK_PATH", "/rerank")
        self.chat_path = chat_path or os.environ.get("NEBULABLOCK_CHAT_PATH", "/chat/completions")

        self.timeout = timeout

    # ------------------------------ HTTP ------------------------------ #
    def _request(self, path: str, payload: Dict[str, Any], max_retries: int = 3) -> Dict[str, Any]:
        if not self.base_url:
            raise RuntimeError("NEBULABLOCK_BASE_URL is not set.")
        if not self.api_key:
            raise RuntimeError("NEBULABLOCK_API_KEY is not set.")

        url = f"{self.base_url}{path}"
        data = json.dumps(payload).encode("utf-8")
        
        # Create an SSL context that's more tolerant
        import ssl
        ssl_context = ssl.create_default_context()
        ssl_context.check_hostname = False
        ssl_context.verify_mode = ssl.CERT_NONE
        
        last_error = None
        for attempt in range(max_retries):
            try:
                req = urllib.request.Request(url, data=data, method="POST")
                
                # Add headers
                req.add_header("Content-Type", "application/json")
                req.add_header("Authorization", f"Bearer {self.api_key}")
                req.add_header("User-Agent", "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36")
                req.add_header("Accept", "application/json")
                req.add_header("Accept-Encoding", "gzip, deflate, br")
                req.add_header("Connection", "keep-alive")
                
                with urllib.request.urlopen(req, timeout=self.timeout, context=ssl_context) as resp:
                    body = resp.read()
                    
                    # Check if response is compressed and decompress accordingly
                    content_encoding = resp.headers.get('Content-Encoding', '').lower()
                    
                    if content_encoding == 'br' and BROTLI_AVAILABLE:
                        try:
                            body = brotli.decompress(body)
                        except Exception as e:
                            raise RuntimeError(f"Failed to decompress Brotli response: {e}")
                    elif content_encoding == 'gzip' or body.startswith(b'\x1f\x8b'):
                        try:
                            body = gzip.decompress(body)
                        except Exception as e:
                            raise RuntimeError(f"Failed to decompress gzip response: {e}")
                    elif content_encoding == 'br' and not BROTLI_AVAILABLE:
                        raise RuntimeError("Response is Brotli compressed but brotli library is not available. Install with: pip install brotli")
                    
                    # Try to decode with UTF-8, fallback to latin-1 if that fails
                    try:
                        text = body.decode("utf-8")
                    except UnicodeDecodeError:
                        text = body.decode("latin-1")
                    
                    # Debug: print response details if it's not valid JSON
                    if not text.strip():
                        raise RuntimeError(f"Empty response from {url}")
                    
                    try:
                        return json.loads(text)
                    except json.JSONDecodeError as e:
                        # If it's not JSON, show what we actually got
                        raise RuntimeError(f"Invalid JSON response from {url}. Response: {text[:200]}...")
                        
            except urllib.error.HTTPError as e:
                last_error = e
                try:
                    detail = e.read().decode("utf-8", errors="ignore")
                except UnicodeDecodeError:
                    detail = e.read().decode("latin-1", errors="ignore")
                # Add exponential backoff delay
                time.sleep(0.5 * (2 ** attempt))
                if attempt == max_retries - 1:
                    raise RuntimeError(f"HTTPError {e.code} for {url}: {detail}")
                continue
                
            except urllib.error.URLError as e:
                last_error = e
                # Add exponential backoff delay
                time.sleep(0.5 * (2 ** attempt))
                if attempt == max_retries - 1:
                    raise RuntimeError(f"URLError for {url}: {e}")
                continue
                
        # If we get here, all retries failed
        raise RuntimeError(f"Failed after {max_retries} attempts. Last error: {last_error}")

    # ---------------------------- Embeddings -------------------------- #
    def embed(self, texts: List[str]) -> List[List[float]]:
        """
        Calls embeddings endpoint. Assumes payload {"model": ..., "input": [...]}
        and response like {"data": [{"embedding": [...]}, ...]}.
        """
        payload = {"model": self.embedding_model, "input": texts}
        resp = self._request(self.embeddings_path, payload)

        data = resp.get("data")
        if not isinstance(data, list):
            raise RuntimeError(f"Unexpected embeddings response: {resp}")
        out: List[List[float]] = []
        for item in data:
            emb = item.get("embedding")
            if not isinstance(emb, list):
                raise RuntimeError(f"Missing 'embedding' in item: {item}")
            out.append([float(x) for x in emb])
        return out

    # ----------------------------- Reranker --------------------------- #
    def rerank(
        self,
        query: str,
        documents: List[str],
        top_n: Optional[int] = None,
        return_documents: bool = False,
    ) -> List[Dict[str, Any]]:
        """
        Calls rerank endpoint. Assumes Cohere-like payload and response:
          payload: { model, query, documents: ["...", ...], top_n }
          response: { results: [ {index, relevance_score, document?}, ... ] }
        """
        payload: Dict[str, Any] = {
            "model": self.reranker_model,
            "query": query,
            "documents": documents,
        }
        if top_n is not None:
            payload["top_n"] = int(top_n)
        if return_documents:
            payload["return_documents"] = True

        resp = self._request(self.rerank_path, payload)
        results = resp.get("results") or resp.get("data")
        if not isinstance(results, list):
            raise RuntimeError(f"Unexpected rerank response: {resp}")
        return results

    # ------------------------------- Chat ----------------------------- #
    def chat(self, messages: List[Dict[str, str]], temperature: float = 0.2, max_tokens: Optional[int] = None) -> str:
        """
        Calls chat/completions endpoint. Assumes OpenAI-like payload/response.
        """
        payload: Dict[str, Any] = {
            "model": self.chat_model,
            "messages": messages,
            "temperature": float(temperature),
        }
        if max_tokens is not None:
            payload["max_tokens"] = int(max_tokens)

        resp = self._request(self.chat_path, payload)
        choices = resp.get("choices")
        if not isinstance(choices, list) or not choices:
            raise RuntimeError(f"Unexpected chat response: {resp}")
        message = choices[0].get("message") or {}
        content = message.get("content")
        if not isinstance(content, str):
            raise RuntimeError(f"Missing content in chat response: {resp}")
        
        # Ensure content is properly decoded
        if isinstance(content, bytes):
            try:
                content = content.decode("utf-8")
            except UnicodeDecodeError:
                content = content.decode("latin-1", errors="ignore")
        
        return content
